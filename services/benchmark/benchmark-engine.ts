/**
 * TORP Benchmark Engine
 * Syst√®me de mesure de performance et de validation de l'algorithme de scoring
 */

import type { Devis, TORPScore } from '@/types'
import { prisma } from '@/lib/prisma'

export interface BenchmarkMetrics {
  // M√©triques de pr√©cision
  accuracy: {
    scorePredictionAccuracy: number // Pr√©cision des pr√©dictions de score
    gradePredictionAccuracy: number // Pr√©cision des pr√©dictions de grade
    priceEstimationAccuracy: number // Pr√©cision des estimations de prix
  }
  
  // M√©triques de coh√©rence
  consistency: {
    scoreStability: number // Stabilit√© du score sur diff√©rents passages
    interRaterReliability: number // Coh√©rence entre diff√©rents √©valuateurs
    temporalConsistency: number // Coh√©rence temporelle
  }
  
  // M√©triques de performance des donn√©es
  dataQuality: {
    dataCompleteness: number // Taux de compl√©tude des donn√©es
    dataFreshness: number // Fra√Æcheur des donn√©es (√¢ge moyen)
    sourceReliability: number // Fiabilit√© des sources
    enrichmentSuccessRate: number // Taux de succ√®s de l'enrichissement
  }
  
  // M√©triques algorithmiques
  algorithmPerformance: {
    scoringSpeed: number // Temps moyen de calcul du score (ms)
    criteriaCoverage: number // Pourcentage de crit√®res √©valu√©s
    falsePositiveRate: number // Taux de faux positifs
    falseNegativeRate: number // Taux de faux n√©gatifs
  }
  
  // M√©triques business
  businessImpact: {
    userSatisfaction: number // Satisfaction utilisateur (si disponible)
    recommendationAccuracy: number // Pr√©cision des recommandations
    alertPrecision: number // Pr√©cision des alertes
  }
}

export interface BenchmarkResult {
  timestamp: string
  version: string
  metrics: BenchmarkMetrics
  sampleSize: number
  testCases: BenchmarkTestCase[]
  recommendations: string[]
}

export interface BenchmarkTestCase {
  devisId: string
  expectedGrade?: string
  actualGrade: string
  scoreDeviation?: number
  dataCompleteness: number
  sourcesUsed: string[]
  processingTime: number
  errors?: string[]
}

export class BenchmarkEngine {
  private readonly version: string = '1.0.0'

  /**
   * Ex√©cute un benchmark complet sur un √©chantillon de devis
   */
  async runBenchmark(
    sampleSize: number = 100,
    dateRange?: { start: Date; end: Date }
  ): Promise<BenchmarkResult> {
    console.log(`[BenchmarkEngine] üöÄ D√©marrage benchmark v${this.version}`)
    console.log(`[BenchmarkEngine] üìä √âchantillon: ${sampleSize} devis`)

    // 1. S√©lectionner un √©chantillon repr√©sentatif
    const testCases = await this.selectSample(sampleSize, dateRange)
    console.log(`[BenchmarkEngine] ‚úÖ ${testCases.length} devis s√©lectionn√©s`)

    // 2. Calculer les m√©triques de pr√©cision
    const accuracy = await this.calculateAccuracy(testCases)
    console.log(`[BenchmarkEngine] üìà Pr√©cision calcul√©e:`, accuracy)

    // 3. Calculer les m√©triques de coh√©rence
    const consistency = await this.calculateConsistency(testCases)
    console.log(`[BenchmarkEngine] üîÑ Coh√©rence calcul√©e:`, consistency)

    // 4. √âvaluer la qualit√© des donn√©es
    const dataQuality = await this.calculateDataQuality(testCases)
    console.log(`[BenchmarkEngine] üì¶ Qualit√© donn√©es:`, dataQuality)

    // 5. Mesurer la performance algorithmique
    const algorithmPerformance = await this.calculateAlgorithmPerformance(testCases)
    console.log(`[BenchmarkEngine] ‚ö° Performance algorithmique:`, algorithmPerformance)

    // 6. √âvaluer l'impact business
    const businessImpact = await this.calculateBusinessImpact(testCases)
    console.log(`[BenchmarkEngine] üíº Impact business:`, businessImpact)

    // 7. G√©n√©rer des recommandations
    const recommendations = this.generateRecommendations({
      accuracy,
      consistency,
      dataQuality,
      algorithmPerformance,
      businessImpact,
    })

    const metrics: BenchmarkMetrics = {
      accuracy,
      consistency,
      dataQuality,
      algorithmPerformance,
      businessImpact,
    }

    return {
      timestamp: new Date().toISOString(),
      version: this.version,
      metrics,
      sampleSize: testCases.length,
      testCases,
      recommendations,
    }
  }

  /**
   * S√©lectionne un √©chantillon repr√©sentatif de devis
   */
  private async selectSample(
    size: number,
    dateRange?: { start: Date; end: Date }
  ): Promise<BenchmarkTestCase[]> {
    const whereClause: any = {}
    
    if (dateRange) {
      whereClause.createdAt = {
        gte: dateRange.start,
        lte: dateRange.end,
      }
    }

    const devis = await prisma.devis.findMany({
      where: whereClause,
      take: size,
      orderBy: { createdAt: 'desc' },
      include: {
        torpScores: {
          orderBy: { createdAt: 'desc' },
          take: 1,
        },
      },
    })

    return devis.map((devis) => {
      const latestScore = devis.torpScores[0]
      const extractedData = devis.extractedData as any
      
      // Calculer la compl√©tude des donn√©es
      const dataCompleteness = this.calculateDataCompleteness(devis)
      
      // Identifier les sources utilis√©es
      const sourcesUsed = this.identifySources(devis)

      return {
        devisId: devis.id,
        actualGrade: latestScore?.scoreGrade || 'E',
        scoreDeviation: latestScore ? undefined : 0, // √Ä am√©liorer avec validation manuelle
        dataCompleteness,
        sourcesUsed,
        processingTime: 0, // √Ä mesurer lors du recalcul
        errors: [],
      }
    })
  }

  /**
   * Calcule la compl√©tude des donn√©es pour un devis
   */
  private calculateDataCompleteness(devis: any): number {
    const extractedData = devis.extractedData as any || {}
    let totalFields = 0
    let filledFields = 0

    // Champs essentiels
    const essentialFields = [
      'totalAmount',
      'company.name',
      'company.siret',
      'items',
      'project.type',
    ]

    essentialFields.forEach((field) => {
      totalFields++
      const value = this.getNestedValue(extractedData, field)
      if (value !== null && value !== undefined && value !== '') {
        filledFields++
      }
    })

    // Items d√©taill√©s
    if (extractedData.items && Array.isArray(extractedData.items)) {
      extractedData.items.forEach((item: any) => {
        totalFields += 4 // description, quantity, unitPrice, totalPrice
        if (item.description) filledFields++
        if (item.quantity) filledFields++
        if (item.unitPrice) filledFields++
        if (item.totalPrice) filledFields++
      })
    }

    return totalFields > 0 ? (filledFields / totalFields) * 100 : 0
  }

  /**
   * Identifie les sources de donn√©es utilis√©es
   */
  private identifySources(devis: any): string[] {
    const sources: string[] = []
    const enrichedData = devis.enrichedData as any || {}

    if (enrichedData.company?.siret) sources.push('Sirene')
    if (enrichedData.priceReferences?.length) sources.push('PriceReferences')
    if (enrichedData.regionalData) sources.push('RegionalData')
    if (enrichedData.complianceData) sources.push('ComplianceData')
    if (enrichedData.dtus?.length) sources.push('DTU')
    
    // V√©rifier les donn√©es enrichies via l'enrichissement avanc√©
    if (enrichedData.company?.financialData) sources.push('Infogreffe')
    
    return sources
  }

  /**
   * Calcule les m√©triques de pr√©cision
   */
  private async calculateAccuracy(testCases: BenchmarkTestCase[]): Promise<BenchmarkMetrics['accuracy']> {
    // Pour l'instant, on calcule la coh√©rence interne
    // √Ä am√©liorer avec des donn√©es de validation manuelle
    const scores = testCases
      .filter((tc) => tc.scoreDeviation !== undefined)
      .map((tc) => tc.scoreDeviation || 0)

    const avgDeviation = scores.length > 0
      ? scores.reduce((a, b) => a + Math.abs(b), 0) / scores.length
      : 0

    return {
      scorePredictionAccuracy: Math.max(0, 100 - avgDeviation * 10),
      gradePredictionAccuracy: 75, // Placeholder - n√©cessite validation manuelle
      priceEstimationAccuracy: 80, // Placeholder - n√©cessite validation manuelle
    }
  }

  /**
   * Calcule les m√©triques de coh√©rence
   */
  private async calculateConsistency(testCases: BenchmarkTestCase[]): Promise<BenchmarkMetrics['consistency']> {
    // Stabilit√© : mesure la variance des scores pour des devis similaires
    const gradeDistribution: Record<string, number> = {}
    testCases.forEach((tc) => {
      gradeDistribution[tc.actualGrade] = (gradeDistribution[tc.actualGrade] || 0) + 1
    })

    // Calculer l'entropie pour mesurer la distribution
    const total = testCases.length
    const entropy = Object.values(gradeDistribution).reduce((sum, count) => {
      const p = count / total
      return sum - (p > 0 ? p * Math.log2(p) : 0)
    }, 0)
    
    // Normaliser entre 0 et 100 (max entropy = log2(5) pour 5 grades)
    const maxEntropy = Math.log2(5)
    const consistencyScore = (entropy / maxEntropy) * 100

    return {
      scoreStability: 85, // Placeholder - n√©cessite recalculs multiples
      interRaterReliability: 80, // Placeholder - n√©cessite validation manuelle
      temporalConsistency: consistencyScore,
    }
  }

  /**
   * Calcule la qualit√© des donn√©es
   */
  private async calculateDataQuality(testCases: BenchmarkTestCase[]): Promise<BenchmarkMetrics['dataQuality']> {
    const completenessScores = testCases.map((tc) => tc.dataCompleteness)
    const avgCompleteness = completenessScores.reduce((a, b) => a + b, 0) / completenessScores.length

    const uniqueSources = new Set<string>()
    testCases.forEach((tc) => {
      tc.sourcesUsed.forEach((source) => uniqueSources.add(source))
    })

    const avgSourcesPerDevis = testCases.reduce((sum, tc) => sum + tc.sourcesUsed.length, 0) / testCases.length

    return {
      dataCompleteness: avgCompleteness,
      dataFreshness: 75, // Placeholder - n√©cessite tracking de dates
      sourceReliability: Math.min(100, avgSourcesPerDevis * 15), // Bas√© sur le nombre de sources
      enrichmentSuccessRate: (testCases.filter((tc) => tc.sourcesUsed.length > 0).length / testCases.length) * 100,
    }
  }

  /**
   * Calcule la performance algorithmique
   */
  private async calculateAlgorithmPerformance(testCases: BenchmarkTestCase[]): Promise<BenchmarkMetrics['algorithmPerformance']> {
    const processingTimes = testCases.map((tc) => tc.processingTime).filter((t) => t > 0)
    const avgProcessingTime = processingTimes.length > 0
      ? processingTimes.reduce((a, b) => a + b, 0) / processingTimes.length
      : 500 // Valeur par d√©faut

    // Tous les devis ont un score, donc 100% de couverture
    const criteriaCoverage = 100 // Placeholder - n√©cessite analyse d√©taill√©e

    return {
      scoringSpeed: avgProcessingTime,
      criteriaCoverage,
      falsePositiveRate: 5, // Placeholder - n√©cessite validation manuelle
      falseNegativeRate: 8, // Placeholder - n√©cessite validation manuelle
    }
  }

  /**
   * Calcule l'impact business
   */
  private async calculateBusinessImpact(testCases: BenchmarkTestCase[]): Promise<BenchmarkMetrics['businessImpact']> {
    // Pour l'instant, m√©triques bas√©es sur les donn√©es disponibles
    const gradeDistribution: Record<string, number> = {}
    testCases.forEach((tc) => {
      gradeDistribution[tc.actualGrade] = (gradeDistribution[tc.actualGrade] || 0) + 1
    })

    // Diversit√© des grades = meilleure discrimination
    const diversity = Object.keys(gradeDistribution).length / 5 // 5 grades possibles (A-E)

    return {
      userSatisfaction: 75, // Placeholder - n√©cessite feedback utilisateurs
      recommendationAccuracy: 80, // Placeholder - n√©cessite validation
      alertPrecision: 85, // Placeholder - n√©cessite validation
    }
  }

  /**
   * G√©n√®re des recommandations bas√©es sur les m√©triques
   */
  private generateRecommendations(metrics: BenchmarkMetrics): string[] {
    const recommendations: string[] = []

    // Pr√©cision
    if (metrics.accuracy.scorePredictionAccuracy < 80) {
      recommendations.push('Am√©liorer la pr√©cision de pr√©diction des scores (actuellement ' + 
        metrics.accuracy.scorePredictionAccuracy.toFixed(1) + '%)')
    }

    // Qualit√© des donn√©es
    if (metrics.dataQuality.dataCompleteness < 70) {
      recommendations.push('Am√©liorer la compl√©tude des donn√©es extraites (actuellement ' + 
        metrics.dataQuality.dataCompleteness.toFixed(1) + '%)')
    }

    if (metrics.dataQuality.enrichmentSuccessRate < 60) {
      recommendations.push('Augmenter le taux de succ√®s de l\'enrichissement (actuellement ' + 
        metrics.dataQuality.enrichmentSuccessRate.toFixed(1) + '%)')
    }

    if (metrics.dataQuality.sourceReliability < 60) {
      recommendations.push('Augmenter le nombre de sources de donn√©es par devis')
    }

    // Performance
    if (metrics.algorithmPerformance.scoringSpeed > 2000) {
      recommendations.push('Optimiser la vitesse de calcul du score (actuellement ' + 
        metrics.algorithmPerformance.scoringSpeed.toFixed(0) + 'ms)')
    }

    // Coh√©rence
    if (metrics.consistency.scoreStability < 80) {
      recommendations.push('Am√©liorer la stabilit√© du score entre diff√©rents passages')
    }

    if (recommendations.length === 0) {
      recommendations.push('Les m√©triques sont satisfaisantes. Continuer le monitoring.')
    }

    return recommendations
  }

  /**
   * Helper pour acc√©der aux valeurs imbriqu√©es
   */
  private getNestedValue(obj: any, path: string): any {
    return path.split('.').reduce((current, prop) => current?.[prop], obj)
  }
}

