# ü§ñ Int√©gration GPT - Guide Simple

## ‚úÖ Ce qui est fait

Votre plateforme TORP peut maintenant **appeler automatiquement votre GPT** pour analyser les devis.

**Flux :**
```
Utilisateur upload devis ‚Üí TORP appelle GPT ‚Üí GPT analyse ‚Üí R√©sultat stock√© en BDD
```

---

## üöÄ Configuration (3 minutes)

### 1Ô∏è‚É£ Ajouter la cl√© API OpenAI

Dans Vercel (Settings ‚Üí Environment Variables) :

```
OPENAI_API_KEY=sk-votre-cle-openai
```

**O√π trouver votre cl√© ?**
üëâ https://platform.openai.com/api-keys

### 2Ô∏è‚É£ D√©ployer

```bash
git push
```

Le d√©ploiement appliquera automatiquement la migration Prisma.

### 3Ô∏è‚É£ Tester

Appelez l'endpoint pour analyser un devis :

```bash
curl -X POST https://torp-25.vercel.app/api/devis/VOTRE_DEVIS_ID/analyze-gpt
```

**C'est tout ! ‚ú®**

---

## üìù Comment l'utiliser

### Option A : Automatique (recommand√©)

Dans votre code, apr√®s la cr√©ation d'un devis :

```typescript
import { analyzeDevisWithGPT } from '@/services/gpt/gpt-analyzer-service';

// Apr√®s avoir cr√©√© le devis
const devis = await prisma.devis.create({...});

// Lancer l'analyse en arri√®re-plan
analyzeDevisWithGPT(devis.id);
```

### Option B : Bouton manuel

Ajoutez un bouton "Analyser avec IA" dans votre interface :

```typescript
async function handleAnalyze(devisId: string) {
  const response = await fetch(`/api/devis/${devisId}/analyze-gpt`, {
    method: 'POST'
  });

  const data = await response.json();
  alert(data.message);
}
```

### Option C : Afficher l'analyse

```typescript
// R√©cup√©rer l'analyse GPT
const response = await fetch(`/api/devis/${devisId}/gpt-analysis`);
const { data: analysis } = await response.json();

// Afficher
console.log('Score:', analysis.gptScore);
console.log('Grade:', analysis.gptGrade);
console.log('Recommandations:', analysis.recommendations);
```

---

## üìä Ce que le GPT analyse

Le GPT analyse le devis selon 4 crit√®res :
- **Prix (25%)** : Comparaison au march√©
- **Qualit√© (30%)** : Certifications, sant√© financi√®re
- **Conformit√© (25%)** : Normes, garanties
- **D√©lais (20%)** : R√©alisme

**R√©sultat :**
```json
{
  "score": 75,
  "grade": "B",
  "confidence": 85,
  "analysis": {
    "summary": "R√©sum√© de l'analyse",
    "details": {...}
  },
  "recommendations": [...],
  "alerts": [...],
  "strengths": [...],
  "weaknesses": [...]
}
```

---

## üí∞ Co√ªt

Environ **3.5 centimes par analyse** (mod√®le gpt-4-turbo-preview)

1000 analyses/mois = ~35‚Ç¨/mois

---

## üîß API Endpoints

| Endpoint | M√©thode | Description |
|----------|---------|-------------|
| `/api/devis/[id]/analyze-gpt` | POST | D√©clenche l'analyse GPT |
| `/api/devis/[id]/gpt-analysis` | GET | R√©cup√®re l'analyse existante |

---

## üìö Documentation compl√®te

üëâ Voir `GUIDE_INTEGRATION_GPT_PLATEFORME.md` pour :
- Exemples de code d√©taill√©s
- Configuration avanc√©e
- Personnalisation du prompt
- D√©pannage

---

## üéØ R√©sum√©

**Fichiers cr√©√©s :**
- `/services/gpt/gpt-analyzer-service.ts` - Service principal
- `/app/api/devis/[id]/analyze-gpt/route.ts` - Endpoint POST
- `/app/api/devis/[id]/gpt-analysis/route.ts` - Endpoint GET

**Ce qu'il faut faire :**
1. ‚úÖ Ajouter `OPENAI_API_KEY` dans Vercel
2. ‚úÖ D√©ployer
3. ‚úÖ Appeler l'endpoint pour tester
4. ‚úÖ Int√©grer dans votre code

**Temps : 3 minutes**

---

## ‚ùì FAQ

**Q : C'est diff√©rent de ChatGPT ?**
A : Oui ! Ici, c'est votre plateforme qui appelle directement l'API OpenAI. Pas besoin de configurer ChatGPT.

**Q : Mon GPT personnalis√© est utilis√© ?**
A : Non, on utilise directement l'API OpenAI avec un prompt personnalis√© dans le code.

**Q : Je veux utiliser mon GPT de ChatGPT ?**
A : C'est possible mais plus complexe. L'API OpenAI ne supporte pas encore les GPTs personnalis√©s via API.

**Q : Le d√©ploiement a √©chou√© ?**
A : V√©rifiez les logs Vercel. L'erreur devrait √™tre corrig√©e maintenant.

---

**Version** : 2.0.0 | **Date** : 2025-11-11
