# üîÑ Syst√®me de Scraping et Collecte de Donn√©es - TORP

## Vue d'Ensemble

Le syst√®me de scraping interne permet d'enrichir automatiquement la base de donn√©es sans surcharger le flux principal, avec planification horaire et traitement par batch.

## üîß Architecture

### 1. Data Scraper Service

**Fichier**: `services/scraping/data-scraper.ts`

**Fonctionnalit√©s**:
- Queue de t√¢ches avec priorit√©s (low, medium, high)
- Traitement par batch (10 t√¢ches max par ex√©cution)
- Intervalle minimum de 15 minutes entre batches
- Retry automatique avec backoff exponentiel
- Cache pour √©viter les doublons

**Types de scraping**:
- `price`: Donn√©es de prix par cat√©gorie/r√©gion
- `cadastre`: Donn√©es cadastrales par adresse
- `georisques`: Risques naturels par adresse
- `company`: Donn√©es entreprise par SIRET
- `compliance`: Donn√©es de conformit√© (DTU, normes)

### 2. Training Data Collector

**Fichier**: `services/training/data-collector.ts`

**Fonctionnalit√©s**:
- Collecte automatique depuis devis existants
- Extraction de features ML
- Validation et nettoyage des donn√©es
- Export en JSON pour entra√Ænement
- Calcul de statistiques

### 3. A/B Testing Engine

**Fichier**: `services/ab-testing/ab-test-engine.ts`

**Fonctionnalit√©s**:
- Configuration de tests A/B
- Distribution d√©terministe (hash-based)
- Comparaison statistique (t-test)
- Recommandations automatiques

## üöÄ Utilisation

### Scraping

**API Endpoints**:
- `POST /api/scraping/process` - Traiter la queue (√† appeler p√©riodiquement)
- `GET /api/scraping/process` - Statistiques de la queue

**Script**:
```bash
# Ex√©cuter le scheduler (toutes les heures)
npx tsx scripts/scraping-scheduler.ts
```

**Planification automatique**:
Le scraping est automatiquement programm√© lors de la cr√©ation d'un nouveau devis :
- Entreprise (SIRET) ‚Üí priorit√© haute, imm√©diat
- Prix ‚Üí priorit√© moyenne, d√©lai 5 min
- Cadastre ‚Üí priorit√© basse, d√©lai 10 min
- G√©orisques ‚Üí priorit√© basse, d√©lai 15 min

### Collecte de Donn√©es d'Entra√Ænement

**API Endpoint**:
```bash
POST /api/training/collect
{
  "limit": 100,
  "startDate": "2024-01-01T00:00:00Z",
  "endDate": "2024-12-31T23:59:59Z"
}
```

**R√©sultat**:
- Dataset complet avec features ML
- Statistiques d√©taill√©es
- Validation automatique
- Pr√™t pour entra√Ænement

### A/B Testing

**Cr√©er un test**:
```bash
POST /api/ab-test/create
{
  "testId": "ml_vs_baseline",
  "name": "ML vs Baseline",
  "trafficSplit": 0.5,
  "variants": {
    "control": { "useML": false, "version": "2.0.0" },
    "variant": { "useML": true, "version": "2.1.0" }
  }
}
```

**Comparer les r√©sultats**:
```typescript
const comparison = await abEngine.compareTest('ml_vs_baseline')
console.log(`Am√©lioration: ${comparison.improvement.scoreAccuracy}%`)
console.log(`Recommandation: ${comparison.recommendation}`)
```

## ‚öôÔ∏è Configuration Cron

### Vercel Cron Jobs

Dans `vercel.json`:
```json
{
  "crons": [
    {
      "path": "/api/scraping/process",
      "schedule": "0 * * * *"
    }
  ]
}
```

### Alternative: Script Node

```bash
# Cron job local (toutes les heures)
0 * * * * cd /path/to/project && npx tsx scripts/scraping-scheduler.ts
```

## üìä Monitoring

### Statistiques de Queue

```typescript
const stats = globalScraper.getQueueStats()
// {
//   total: 45,
//   pending: 30,
//   inProgress: 5,
//   completed: 8,
//   failed: 2
// }
```

### Logs

Tous les √©v√©nements sont logg√©s avec pr√©fixes :
- `[DataScraper]` - Scraping
- `[TrainingCollector]` - Collecte donn√©es
- `[ABTestEngine]` - Tests A/B

## üéØ Workflow Complet

1. **Cr√©ation Devis** ‚Üí Scraping programm√© automatiquement
2. **Scheduler** ‚Üí Traite la queue toutes les heures
3. **Collecte** ‚Üí Donn√©es agr√©g√©es pour entra√Ænement
4. **Entra√Ænement ML** ‚Üí Mod√®les am√©lior√©s
5. **A/B Testing** ‚Üí Validation des am√©liorations
6. **D√©ploiement** ‚Üí Version optimale mise en production

## üìà M√©triques Attendues

| M√©trique | Objectif |
|----------|----------|
| Taux de succ√®s scraping | ‚â• 85% |
| Temps moyen traitement | < 5s par batch |
| Compl√©tude donn√©es enrichies | ‚â• 70% |
| Qualit√© dataset entra√Ænement | ‚â• 80% valides |
| Significativit√© tests A/B | p < 0.05 |

## üîÑ Am√©liorations Futures

1. **Scraping intelligent**: Prioriser selon criticit√©
2. **Cache distribu√©**: Redis pour cache partag√©
3. **ML en temps r√©el**: Entra√Ænement continu
4. **Dashboard monitoring**: Vue en temps r√©el des queues
5. **Alertes**: Notifications sur √©checs critiques

