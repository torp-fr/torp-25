#!/usr/bin/env tsx
/**
 * Script de planification du scraping
 * Ã€ exÃ©cuter toutes les heures via cron job
 */

import { globalScraper } from '../services/scraping/data-scraper'
import { prisma } from '../lib/db'

async function main() {
  console.log('ğŸ• Scraping Scheduler - DÃ©marrage...\n')

  try {
    // 1. RÃ©cupÃ©rer les nouveaux devis sans scraping
    const recentDevis = await prisma.devis.findMany({
      where: {
        createdAt: {
          gte: new Date(Date.now() - 1000 * 60 * 60 * 24), // DerniÃ¨res 24h
        },
      },
      take: 50,
      orderBy: { createdAt: 'desc' },
    })

    console.log(`ğŸ“‹ ${recentDevis.length} devis rÃ©cents trouvÃ©s\n`)

    // 2. Programmer le scraping pour chaque devis
    for (const devis of recentDevis) {
      await globalScraper.scheduleDevisScraping(devis.id)
    }

    // 3. Traiter la queue
    console.log('\nğŸš€ Traitement de la queue...\n')
    await globalScraper.processQueue()

    // 4. Afficher les statistiques
    const stats = globalScraper.getQueueStats()
    console.log('\nğŸ“Š Statistiques:')
    console.log(`  Total: ${stats.total}`)
    console.log(`  En attente: ${stats.pending}`)
    console.log(`  En cours: ${stats.inProgress}`)
    console.log(`  ComplÃ©tÃ©es: ${stats.completed}`)
    console.log(`  Ã‰chouÃ©es: ${stats.failed}\n`)

    console.log('âœ… Scraping scheduler terminÃ©\n')

  } catch (error) {
    console.error('âŒ Erreur:', error)
    process.exit(1)
  } finally {
    await prisma.$disconnect()
  }
}

main()

